{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: conda: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "from model import ContextEncoder, AspectAttnDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'electronics'\n",
    "model_info = '2_512_1024/'\n",
    "model_save_dir = './data/{}/model/{}'.format(dataset_name, model_info)\n",
    "model_file = '_411_aspect_planning_355k.tar'\n",
    "\n",
    "model_state_dict = torch.load(os.path.join(model_save_dir, model_file))\n",
    "\n",
    "#model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect learned representations\n",
    "- See how learned concatenated embeddings (for each context) are discriminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Got 5 and 40405 (The offending index is 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-94178ad13fef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mr_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_state_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoder'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r_embedding.weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mc_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu_embs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_embs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_embs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mc_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Got 5 and 40405 (The offending index is 0)"
     ]
    }
   ],
   "source": [
    "u_embs = model_state_dict['encoder']['u_embedding.weight']\n",
    "i_embs = model_state_dict['encoder']['i_embedding.weight']\n",
    "r_embs = model_state_dict['encoder']['r_embedding.weight']\n",
    "\n",
    "c_embs = torch.cat([u_embs, i_embs, r_embs], dim=1)\n",
    "c_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 512])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ContextEncoder()\n",
    "encoder_out, encoder_hidden = encoder(attr_input)\n",
    "\n",
    "encoder = ContextEncoder(context_embed_size, num_contexts, hidden_size, context_embeddings, n_layers)\n",
    "\n",
    "aspect_emb = nn.Embedding(vocab.n_topics, embed_size)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect log probabilities\n",
    "- Run test with a small set\n",
    "- See log probabilities in the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers, hidden, batch_size:  2 128 2048\n",
      "Start loading training data ...\n",
      "# train instances:  173964\n",
      "testing the model \"./data/electronics/model/2_128_2048/118_aspect_planning.tar\"\n",
      "Building encoder and decoder ...\n",
      "cuda is available? 0(device id: 0) (among 8 available ones)\n",
      "encoder:  cpu\n",
      "=============================================================\n",
      "Attribute >  A17X6Q4GWWK3VI\tB006FXA78G\t5\n",
      "Aspects >  battery\n",
      "/home/yongsu/aspect/evaluate.py:296: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  attr_input = Variable(torch.LongTensor([sentence]), volatile=True)\n",
      "Evaluate with beam_decoder\n",
      "max_length and beam size:  10 4\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "top_ids:  tensor([   1,  140, 1915, 2144, 1674, 1822,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'price', 'camera', 'product', 'quality', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1915, 2144, 1674, 1822,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'price', 'camera', 'product', 'quality', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1915, 2144, 1674, 1822,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'price', 'camera', 'product', 'quality', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1915, 2144, 1674, 1822,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'price', 'camera', 'product', 'quality', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1822, 2144, 1674, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'quality', 'camera', 'product', 'price', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1822, 2144, 1674, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'quality', 'camera', 'product', 'price', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1822, 2144, 1674, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'quality', 'camera', 'product', 'price', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1822, 2144, 1674, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'quality', 'camera', 'product', 'price', 'screen', 'drive']\n",
      "hyps_sorted:  [0, tensor(140), tensor(1)] [0.0, tensor(1.4593), tensor(1.9421)]\n",
      "best_hyp:  [0, tensor(140), tensor(1)]\n",
      "output words and idx:  ['<sos>', 'sound', '<eos>'] [0, 140, 1]\n",
      "Generation >  sound\n",
      "=============================================================\n",
      "Attribute >  A2TPUSN206QC7A\tB005LAZK5E\t4\n",
      "Aspects >  replacement buy\n",
      "Evaluate with beam_decoder\n",
      "max_length and beam size:  10 4\n",
      "top_ids:  tensor([   1, 1822,  140, 2144, 1674, 1915, 1899,  303])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'camera', 'product', 'price', 'drive', 'screen']\n",
      "top_ids:  tensor([   1, 1822,  140, 2144, 1674, 1915, 1899,  303])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'camera', 'product', 'price', 'drive', 'screen']\n",
      "top_ids:  tensor([   1, 1822,  140, 2144, 1674, 1915, 1899,  303])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'camera', 'product', 'price', 'drive', 'screen']\n",
      "top_ids:  tensor([   1, 1822,  140, 2144, 1674, 1915, 1899,  303])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'camera', 'product', 'price', 'drive', 'screen']\n",
      "top_ids:  tensor([   1, 1822,  140, 1674, 2144, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'product', 'camera', 'price', 'screen', 'drive']\n",
      "top_ids:  tensor([   1, 1822,  140, 1674, 2144, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'product', 'camera', 'price', 'screen', 'drive']\n",
      "top_ids:  tensor([   1, 1822,  140, 1674, 2144, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'product', 'camera', 'price', 'screen', 'drive']\n",
      "top_ids:  tensor([   1, 1822,  140, 1674, 2144, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'product', 'camera', 'price', 'screen', 'drive']\n",
      "hyps_sorted:  [0, tensor(1822), tensor(1)] [0.0, tensor(1.4476), tensor(1.9963)]\n",
      "best_hyp:  [0, tensor(1822), tensor(1)]\n",
      "output words and idx:  ['<sos>', 'quality', '<eos>'] [0, 1822, 1]\n",
      "Generation >  quality\n",
      "=============================================================\n",
      "Attribute >  A2N75ADJSRW0AH\tB0095F5AFG\t4\n",
      "Aspects >  photos sharpness features lens functionality pocket camera camera camera camera camera camera camera mode image quality performance shutter release drive\n",
      "Evaluate with beam_decoder\n",
      "max_length and beam size:  10 4\n",
      "top_ids:  tensor([1915,    1, 2144,  140, 1674, 1822, 1899, 1982])\n",
      "topk_aspects:  ['price', '<eos>', 'camera', 'sound', 'product', 'quality', 'drive', 'unit']\n",
      "top_ids:  tensor([1915,    1, 2144,  140, 1674, 1822, 1899, 1982])\n",
      "topk_aspects:  ['price', '<eos>', 'camera', 'sound', 'product', 'quality', 'drive', 'unit']\n",
      "top_ids:  tensor([1915,    1, 2144,  140, 1674, 1822, 1899, 1982])\n",
      "topk_aspects:  ['price', '<eos>', 'camera', 'sound', 'product', 'quality', 'drive', 'unit']\n",
      "top_ids:  tensor([1915,    1, 2144,  140, 1674, 1822, 1899, 1982])\n",
      "topk_aspects:  ['price', '<eos>', 'camera', 'sound', 'product', 'quality', 'drive', 'unit']\n",
      "top_ids:  tensor([   1, 1915, 1822, 2144,  140, 1674, 1899,  303])\n",
      "topk_aspects:  ['<eos>', 'price', 'quality', 'camera', 'sound', 'product', 'drive', 'screen']\n",
      "top_ids:  tensor([   1, 1915, 1822, 2144,  140, 1674, 1899,  303])\n",
      "topk_aspects:  ['<eos>', 'price', 'quality', 'camera', 'sound', 'product', 'drive', 'screen']\n",
      "top_ids:  tensor([   1, 1915, 1822, 2144,  140, 1674, 1899,  303])\n",
      "topk_aspects:  ['<eos>', 'price', 'quality', 'camera', 'sound', 'product', 'drive', 'screen']\n",
      "top_ids:  tensor([   1, 1915, 1822, 2144,  140, 1674, 1899,  303])\n",
      "topk_aspects:  ['<eos>', 'price', 'quality', 'camera', 'sound', 'product', 'drive', 'screen']\n",
      "hyps_sorted:  [0, tensor(1915), tensor(1)] [0.0, tensor(1.4472), tensor(1.8136)]\n",
      "best_hyp:  [0, tensor(1915), tensor(1)]\n",
      "output words and idx:  ['<sos>', 'price', '<eos>'] [0, 1915, 1]\n",
      "Generation >  price\n",
      "=============================================================\n",
      "Attribute >  AT7MC1511EDOJ\tB00H1XKC1Q\t5\n",
      "Aspects >  sound\n",
      "Evaluate with beam_decoder\n",
      "max_length and beam size:  10 4\n",
      "top_ids:  tensor([   1, 1915, 1822, 2144, 1674,  140, 1346,  303])\n",
      "topk_aspects:  ['<eos>', 'price', 'quality', 'camera', 'product', 'sound', 'cable', 'screen']\n",
      "top_ids:  tensor([   1, 1915, 1822, 2144, 1674,  140, 1346,  303])\n",
      "topk_aspects:  ['<eos>', 'price', 'quality', 'camera', 'product', 'sound', 'cable', 'screen']\n",
      "top_ids:  tensor([   1, 1915, 1822, 2144, 1674,  140, 1346,  303])\n",
      "topk_aspects:  ['<eos>', 'price', 'quality', 'camera', 'product', 'sound', 'cable', 'screen']\n",
      "top_ids:  tensor([   1, 1915, 1822, 2144, 1674,  140, 1346,  303])\n",
      "topk_aspects:  ['<eos>', 'price', 'quality', 'camera', 'product', 'sound', 'cable', 'screen']\n",
      "top_ids:  tensor([   1, 1822,  140, 2144, 1674, 1915,  303, 1346])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'camera', 'product', 'price', 'screen', 'cable']\n",
      "top_ids:  tensor([   1, 1822,  140, 2144, 1674, 1915,  303, 1346])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'camera', 'product', 'price', 'screen', 'cable']\n",
      "top_ids:  tensor([   1, 1822,  140, 2144, 1674, 1915,  303, 1346])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'camera', 'product', 'price', 'screen', 'cable']\n",
      "top_ids:  tensor([   1, 1822,  140, 2144, 1674, 1915,  303, 1346])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'camera', 'product', 'price', 'screen', 'cable']\n",
      "hyps_sorted:  [0, tensor(1915), tensor(1)] [0.0, tensor(1.3960), tensor(1.9657)]\n",
      "best_hyp:  [0, tensor(1915), tensor(1)]\n",
      "output words and idx:  ['<sos>', 'price', '<eos>'] [0, 1915, 1]\n",
      "Generation >  price\n",
      "=============================================================\n",
      "Attribute >  A1PIIGG027G3SU\tB002S53LJ2\t4\n",
      "Aspects >  bass sound\n",
      "Evaluate with beam_decoder\n",
      "max_length and beam size:  10 4\n",
      "top_ids:  tensor([   1,  140, 1915, 1674, 1822, 2144,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'price', 'product', 'quality', 'camera', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1915, 1674, 1822, 2144,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'price', 'product', 'quality', 'camera', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1915, 1674, 1822, 2144,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'price', 'product', 'quality', 'camera', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1915, 1674, 1822, 2144,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'price', 'product', 'quality', 'camera', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1822, 1674, 2144, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'quality', 'product', 'camera', 'price', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1822, 1674, 2144, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'quality', 'product', 'camera', 'price', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1822, 1674, 2144, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'quality', 'product', 'camera', 'price', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1822, 1674, 2144, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'quality', 'product', 'camera', 'price', 'screen', 'drive']\n",
      "hyps_sorted:  [0, tensor(140), tensor(1)] [0.0, tensor(1.4071), tensor(1.9611)]\n",
      "best_hyp:  [0, tensor(140), tensor(1)]\n",
      "output words and idx:  ['<sos>', 'sound', '<eos>'] [0, 140, 1]\n",
      "Generation >  sound\n",
      "=============================================================\n",
      "Attribute >  A6U3HH78QJDVM\tB0028N7442\t5\n",
      "Aspects >  price improvement quality\n",
      "Evaluate with beam_decoder\n",
      "max_length and beam size:  10 4\n",
      "top_ids:  tensor([   1,  140, 1822, 1915, 2144, 1674,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'quality', 'price', 'camera', 'product', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1822, 1915, 2144, 1674,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'quality', 'price', 'camera', 'product', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1822, 1915, 2144, 1674,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'quality', 'price', 'camera', 'product', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1822, 1915, 2144, 1674,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'quality', 'price', 'camera', 'product', 'screen', 'drive']\n",
      "top_ids:  tensor([   1, 1822,  140, 2144, 1674, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'camera', 'product', 'price', 'screen', 'drive']\n",
      "top_ids:  tensor([   1, 1822,  140, 2144, 1674, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'camera', 'product', 'price', 'screen', 'drive']\n",
      "top_ids:  tensor([   1, 1822,  140, 2144, 1674, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'camera', 'product', 'price', 'screen', 'drive']\n",
      "top_ids:  tensor([   1, 1822,  140, 2144, 1674, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'camera', 'product', 'price', 'screen', 'drive']\n",
      "hyps_sorted:  [0, tensor(140), tensor(1)] [0.0, tensor(1.4350), tensor(1.9697)]\n",
      "best_hyp:  [0, tensor(140), tensor(1)]\n",
      "output words and idx:  ['<sos>', 'sound', '<eos>'] [0, 140, 1]\n",
      "Generation >  sound\n",
      "=============================================================\n",
      "Attribute >  A1JHGHQW6YCOZ0\tB0079M711S\t5\n",
      "Aspects >  quality pictures price\n",
      "Evaluate with beam_decoder\n",
      "max_length and beam size:  10 4\n",
      "top_ids:  tensor([   1, 1822, 1915, 2144,  140, 1674,  303, 2896])\n",
      "topk_aspects:  ['<eos>', 'quality', 'price', 'camera', 'sound', 'product', 'screen', 'speakers']\n",
      "top_ids:  tensor([   1, 1822, 1915, 2144,  140, 1674,  303, 2896])\n",
      "topk_aspects:  ['<eos>', 'quality', 'price', 'camera', 'sound', 'product', 'screen', 'speakers']\n",
      "top_ids:  tensor([   1, 1822, 1915, 2144,  140, 1674,  303, 2896])\n",
      "topk_aspects:  ['<eos>', 'quality', 'price', 'camera', 'sound', 'product', 'screen', 'speakers']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_ids:  tensor([   1, 1822, 1915, 2144,  140, 1674,  303, 2896])\n",
      "topk_aspects:  ['<eos>', 'quality', 'price', 'camera', 'sound', 'product', 'screen', 'speakers']\n",
      "top_ids:  tensor([   1, 1822, 2144,  140, 1915, 1674,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'camera', 'sound', 'price', 'product', 'screen', 'drive']\n",
      "top_ids:  tensor([   1, 1822, 2144,  140, 1915, 1674,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'camera', 'sound', 'price', 'product', 'screen', 'drive']\n",
      "top_ids:  tensor([   1, 1822, 2144,  140, 1915, 1674,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'camera', 'sound', 'price', 'product', 'screen', 'drive']\n",
      "top_ids:  tensor([   1, 1822, 2144,  140, 1915, 1674,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'camera', 'sound', 'price', 'product', 'screen', 'drive']\n",
      "hyps_sorted:  [0, tensor(1822), tensor(1)] [0.0, tensor(1.4672), tensor(1.9436)]\n",
      "best_hyp:  [0, tensor(1822), tensor(1)]\n",
      "output words and idx:  ['<sos>', 'quality', '<eos>'] [0, 1822, 1]\n",
      "Generation >  quality\n",
      "=============================================================\n",
      "Attribute >  A2387DVK1EW16Y\tB003ES5ZUU\t5\n",
      "Aspects >  screen\n",
      "Evaluate with beam_decoder\n",
      "max_length and beam size:  10 4\n",
      "top_ids:  tensor([ 140, 1915, 1822,    1, 1674, 2144, 1899, 2167])\n",
      "topk_aspects:  ['sound', 'price', 'quality', '<eos>', 'product', 'camera', 'drive', 'device']\n",
      "top_ids:  tensor([ 140, 1915, 1822,    1, 1674, 2144, 1899, 2167])\n",
      "topk_aspects:  ['sound', 'price', 'quality', '<eos>', 'product', 'camera', 'drive', 'device']\n",
      "top_ids:  tensor([ 140, 1915, 1822,    1, 1674, 2144, 1899, 2167])\n",
      "topk_aspects:  ['sound', 'price', 'quality', '<eos>', 'product', 'camera', 'drive', 'device']\n",
      "top_ids:  tensor([ 140, 1915, 1822,    1, 1674, 2144, 1899, 2167])\n",
      "topk_aspects:  ['sound', 'price', 'quality', '<eos>', 'product', 'camera', 'drive', 'device']\n",
      "top_ids:  tensor([   1,  140, 1822, 1674, 1915, 2144,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'quality', 'product', 'price', 'camera', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1822, 1674, 1915, 2144,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'quality', 'product', 'price', 'camera', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1822, 1674, 1915, 2144,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'quality', 'product', 'price', 'camera', 'screen', 'drive']\n",
      "top_ids:  tensor([   1,  140, 1822, 1674, 1915, 2144,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'sound', 'quality', 'product', 'price', 'camera', 'screen', 'drive']\n",
      "hyps_sorted:  [0, tensor(140), tensor(1)] [0.0, tensor(1.2873), tensor(1.7994)]\n",
      "best_hyp:  [0, tensor(140), tensor(1)]\n",
      "output words and idx:  ['<sos>', 'sound', '<eos>'] [0, 140, 1]\n",
      "Generation >  sound\n",
      "=============================================================\n",
      "Attribute >  A1SCIVDBOKEW81\tB004JO3L40\t5\n",
      "Aspects >  setup settings\n",
      "Evaluate with beam_decoder\n",
      "max_length and beam size:  10 4\n",
      "top_ids:  tensor([   1, 1822, 1674,  140, 1915, 2144,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'product', 'sound', 'price', 'camera', 'screen', 'drive']\n",
      "top_ids:  tensor([   1, 1822, 1674,  140, 1915, 2144,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'product', 'sound', 'price', 'camera', 'screen', 'drive']\n",
      "top_ids:  tensor([   1, 1822, 1674,  140, 1915, 2144,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'product', 'sound', 'price', 'camera', 'screen', 'drive']\n",
      "top_ids:  tensor([   1, 1822, 1674,  140, 1915, 2144,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'product', 'sound', 'price', 'camera', 'screen', 'drive']\n",
      "top_ids:  tensor([   1, 1822,  140, 1674, 2144, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'product', 'camera', 'price', 'screen', 'drive']\n",
      "top_ids:  tensor([   1, 1822,  140, 1674, 2144, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'product', 'camera', 'price', 'screen', 'drive']\n",
      "top_ids:  tensor([   1, 1822,  140, 1674, 2144, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'product', 'camera', 'price', 'screen', 'drive']\n",
      "top_ids:  tensor([   1, 1822,  140, 1674, 2144, 1915,  303, 1899])\n",
      "topk_aspects:  ['<eos>', 'quality', 'sound', 'product', 'camera', 'price', 'screen', 'drive']\n",
      "hyps_sorted:  [0, tensor(1822), tensor(1)] [0.0, tensor(1.4591), tensor(1.9885)]\n",
      "best_hyp:  [0, tensor(1822), tensor(1)]\n",
      "output words and idx:  ['<sos>', 'quality', '<eos>'] [0, 1822, 1]\n",
      "Generation >  quality\n",
      "=============================================================\n",
      "Attribute >  A3BP83QR4G822S\tB00DR0PDNE\t5\n",
      "Aspects >  tv\n",
      "Evaluate with beam_decoder\n",
      "max_length and beam size:  10 4\n",
      "top_ids:  tensor([   1, 1915, 1822, 1674, 2144,  140, 2167, 1346])\n",
      "topk_aspects:  ['<eos>', 'price', 'quality', 'product', 'camera', 'sound', 'device', 'cable']\n",
      "top_ids:  tensor([   1, 1915, 1822, 1674, 2144,  140, 2167, 1346])\n",
      "topk_aspects:  ['<eos>', 'price', 'quality', 'product', 'camera', 'sound', 'device', 'cable']\n",
      "top_ids:  tensor([   1, 1915, 1822, 1674, 2144,  140, 2167, 1346])\n",
      "topk_aspects:  ['<eos>', 'price', 'quality', 'product', 'camera', 'sound', 'device', 'cable']\n",
      "top_ids:  tensor([   1, 1915, 1822, 1674, 2144,  140, 2167, 1346])\n",
      "topk_aspects:  ['<eos>', 'price', 'quality', 'product', 'camera', 'sound', 'device', 'cable']\n",
      "top_ids:  tensor([   1, 1822, 1915, 1674,  140, 2144,  303, 2167])\n",
      "topk_aspects:  ['<eos>', 'quality', 'price', 'product', 'sound', 'camera', 'screen', 'device']\n",
      "top_ids:  tensor([   1, 1822, 1915, 1674,  140, 2144,  303, 2167])\n",
      "topk_aspects:  ['<eos>', 'quality', 'price', 'product', 'sound', 'camera', 'screen', 'device']\n",
      "top_ids:  tensor([   1, 1822, 1915, 1674,  140, 2144,  303, 2167])\n",
      "topk_aspects:  ['<eos>', 'quality', 'price', 'product', 'sound', 'camera', 'screen', 'device']\n",
      "top_ids:  tensor([   1, 1822, 1915, 1674,  140, 2144,  303, 2167])\n",
      "topk_aspects:  ['<eos>', 'quality', 'price', 'product', 'sound', 'camera', 'screen', 'device']\n",
      "hyps_sorted:  [0, tensor(1915), tensor(1)] [0.0, tensor(1.5118), tensor(1.9461)]\n",
      "best_hyp:  [0, tensor(1915), tensor(1)]\n",
      "output words and idx:  ['<sos>', 'price', '<eos>'] [0, 1915, 1]\n",
      "Generation >  price\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!USE_CUDA=0 python3 main.py --test electronics --save_dir ./data/electronics --model ./data/electronics/model/2_128_2048/118_aspect_planning.tar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(10)[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = [1,2]\n",
    "list2 = [3,4]\n",
    "list1.extend(list2)\n",
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor([1,2,3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_2",
   "language": "python",
   "name": "python3_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
